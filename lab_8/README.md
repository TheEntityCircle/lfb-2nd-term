# Лабораторная 8

Еще одним полезным навыком, который вы можете получить в рамках данного курса, является умения работать с процессами.

После того, как вы написали ваш код, скомпилировали его и слинковали, наступает следующий важный этап - запуск. 
На этом этапе, как вы уже знаете, вначале происходит поиск динамических библиотек, а потом система начинает исполнять ваши инструкции.
Обычно по жизни такого описания достаточно, но иногда нужно больше - например, если вы хотите распараллелить вашу программу.

Для этих целей есть специализированные библиотеки (OpenMP, MPI, OpenCL), а если лезть к видеокартам (что пока рановато), то и еще несколько. 
В рамках этой лабы попробуем сделать примерно то же самое базовыми низкоуровневыми инструментами, чтобы понимать основные механики без тяжеловесного синтаксиса или аккуратного полиморфизма, который скрывает интересные детали.

## Что делаем

Жонглируем процессами.

### 0. Запускаем и смотрим.

Возможно, что-то подобное вы уже делали, но давайте еще раз аккуратно. 

Возьмите файл ```00_waiter.cpp``` или напишите свой, который делает аналогичную вещь - бесконечно ждёт ввода пользователя. 
(*Так мы имитируем зависший или просто очень долгий процесс, чтобы успеть рассмотреть его, пока он не завершился.*)
Скомпилируйте и запустите.

Этот процесс занимает тот терминал, из которого вы его запустили.
Мы можете прервать его через **Ctrl+C** или "свернуть" в фон через **Сtrl+Z**.

К работе с фоном мы вернемся немного позже, а сейчас нам нужно оставить процесс висящим и посмотреть на него через "диспетчер задач".
Для этого вам нужно либо запустить еще один терминал (это будет еще один экземпляр bash, даже если у вас виндоубунта), либо прервать первый процесс и запустить еще один вот так:
```
./a.out &
```
В качестве диспетчера задач удобно использовать top (консольный, черно-белый, обычно установлен по умолчанию) или htop (нужно ставить как отдельный пакет, зато красивый и удобный, тоже консольный).
Запустите его и найдите там ваш процесс.
В самом левом столбце будет его номер в системе (PID, process identificator).

Если вы запустите ваш бинарник несколько раз, у вас появится несколько процессов с одним названием и разными номерами.
*Обратите внимание, что если вы "прячете" процесс при помощи &, он сразу пишет вам его PID.*
Это независимые процессы с независимыми адресными пространствами, друг о друге они не знают.
В других столбцах вы видите прочую информацию о процессах - сколько памяти они занимают, сколько процессорного времени, сколько времени запущены и т.д.

Из htop вы можете довольно удобно управлять процессами - например, передавать им разные сигналы.
Выбрав конкретный процесс стрелками на клавиатуре, нажмите F9, и слева появится список возможных сигналов. 
Они стандартные, можете про них (при желании) почитать отдельно.
Чаще всего вас будет интересовать SIGKILL, который предлагается по умолчанию - так можно завершить процесс.

Поэкспериментируйте с этой механикой, создавая и удаляя процессы.

### 1. Ctrl+Z, background, foreground.

Если кто-то делал это в нулевой лабе, лучше сделайте еще раз и освежите в памяти.

Давайте посмотрим, что произошло, если вы применили Ctrl+Z к зависшему процессу. 
На самом деле, он не исчез. 
Он встал на паузу и ушел в фоновый режим. 
Вы можете найти его в диспетчере задач, он значится в списке, но не ест процессорное время.
Удалить его тоже можно.

Создайте бинарник, который не просто ждет ввода пользователя, а именно зависает, тратя ресурсы процессора - например, бесконечно бегая по циклу и перебирая какой-нибудь массив.
Запустите его, посмотрите на него через htop.
*Можете также сделать бинарник, который тратит память (берет в куче кусочки и не возвращает их на место), а потом посмотреть и на него.*
А теперь спрячьте его в фон через Ctrl+Z и снова посмотрите на диспетчер задач.

Вернуть процесс обратно (и снять с паузы) можно с помощью команды fg – пишете fg и часть названия процесса, он умный, сам найдет нужный (например, fg ./1 или fg a.). Полный список того, что есть в фоне, можно посмотреть командой jobs. Если там несколько с одинаковым названием, обращаться к ним можно по номерам.

Если вы хотите, чтобы процесс висел в фоне, но при этом работал, его можно снять с паузы командой bg. Так же пишете bg ./1, он остается в фоне, его можно смотреть с помощью команды jobs, но в htop вы увидите, что он работает и ест процессор.

Поэкспериментируйте и с этой механикой. 
Посмотрите, как она соотносится с & из предыдущего пункта.
Она несложная, но может оказаться полезной.

### 2. Файлы и синхронизация.

#### 2.1. Запись в файл и ручная синхронизация.

Почитайте код в ```01_waiter_and_file_holder.cpp```.
Он умеет открывать файл, держать его открытым, пока ждёт ввода пользователя, контрольно выводить этот ввод в файл и выходить.

Скомпилируйте этот код и запустите получившийся бинарник.
Спрячьте его в фон, пока он ждем ввода.
Убедитесь, что процесс появился в диспетчере задач, а в файле ```1.txt``` появилось правильное число.
Вытащите процесс из фона, введите ему число и снова проверьте тот же файл.

Теперь запустите несколько процессов, убирая их в фон, пока они ждут ввода.
По очереди вытаскивая их из фона, вводите разные числа.
Проверьте файл - в правильном ли порядке идут числа.

Скорее всего (спойлер), в правильном.
В данном случае вы руками контролируете, кто и в каком порядке пишет в файл. 
Фактически, синхронизируете процессы вручную, подвешивая их до тех пор, пока не произойдет ввод.

#### 2.2. Запись в файл без синхронизации.

А вот пример сильно некорректного поведения, которое стоит посмотреть вживую.
В файле ```03_asynchronous_writing.cpp``` приведен пример кода, который пишет в файл набор чисел.
Каждое число он пишет с новой строки и подписывает своим pid, чтобы нам было удобнее читать лог событий, который получится в ```1.txt```.
*Не забывайте удалять старые версии файла - все эти примеры кода только дописывают в конец и не затирают прошлую версию.*

Скомпилируйте этот пример и запустите один процесс. 
Проверьте, что в файл все вывелось нормально.

Теперь запустите несколько процессов: 
```
./a.out && ./a.out && ./a.out
```
Проверьте содержимое ```1.txt```.
Да, там все аккуратно - процессы пишут в памяти друг после друга, не перемешиваясь.
Это потому, что при таком запуске один процесс ждет завершения другого. 
Вы можете попробовать контролировать этот процесс при помощи ввода с экрана и убедиться в том, что новый запускается только после того, как отработал старый.

А теперь давайте посмотрим на настоящую рассинхронизацию.
Прочитайте и запустите скрипт ```03_execute_asynchronously.sh```. 
Он запустит несколько копий вашего процесса одновременно.
Прочитайте файл с логом - теперь записи между разными pid оказались перемешаны.
Запустите скрипт несколько раз, увеличьте количество копий процесса и посмотрите, что будет с логом.

Обычно это то поведение, которого хочется избежать.
*А когда не получается, тогда и появляются логи с перемешанными timestamp...*

#### 2.3. fork()

Как вы заметили, pid выдаются довольно-таки произвольным образом. 
Если вы хотите обмениваться какой-то информацией между потоками (в том числе, синхронизировать их автоматически), нужно, чтобы они как-то узнали, кому вообще что-то передавать - какому pid. 
Это можно организовать через файлы, можете попробовать что-то поизобретать, если стало интересно.

Но есть более штатный способ.
В Linux есть удобная механика порождения одних процессов другими - простая функция fork().
Как она работает, можно посмотреть в примере ```04_fork.cpp```.
Почитайте этот файл, скомпилируйте его, запустите, спрячьте в фон и посмотрите через htop.
Вы увидите, что из одного процесса появилось два. 

Эти процессы не совсем равноправны. 
Например, если вы завершаете родительский процесс через SIGKILL, то завершаются и все дочерние.
А дочерний вы просто так завершить не сможете.
С этой механикой можно экспериментировать дальше, создавая больше процессов *(погуглите еще fork bomb)*.

Перед тем, как идти дальше, давайте убедимся, что в результате форка получаются разные процессы с независимыми адресными пространствами.
Почитайте, скомпилируйте и запустите файл ```05_fork_with_memory.cpp```. 
Он должен отъедать достаточно большой кусок памяти, чтобы заметить его невооруженным глазом в диспетчере задач.
Если вы раскомментируете форк, то каждый дочерний процесс будет съедать еще один такой же кусок.

#### 2.4. pipe

Итак, мы можем создавать потоки, которые что-то друг о друге знают.
Теперь можно попробовать передавать между ними данные.
Для этого есть много способов, кому интересно больше - можно почитать, например, тут https://biendltb.github.io/tech/inter-process-communication-ipc-in-cpp/ 
Мы попробуем старые добрые пайпы.

Очень-очень минималистичный пример, жестоко ободранный от всего лишнего, лежит в ```06_pipes.cpp```.
Фактически, вы создаете временный файлик, через который перекидываете числа.
Но это реализовано через автоматические системные вызовы и довольно-таки удобно.
Попробуйте прочитать-собрать-запустить, запустить несколько раз очень быстро (его начнет забавно глючить), а потом поэкспериментировать с этой механикой.
*В приличном коде функции создания файлов и приёма/передачи принято обвешивать проверками. Это общение с внешними для программы сущностями, в любой момент что-то может пойти не так. Чтобы из-за этого не падать с нечитаемой ошибкой, а продолжать работу (в том числе, например, падать с читаемой ошибкой), нужно обрабатывать то, что эти функции возвращают, и не полагаться на то, что они "ну наверное сработали". Это ровно та ситуация, где возникают коды возврата, исключения, ассерты и т.д.*

Обратите внимание на синтаксис всех функций, которые обращаются с процессами.
Это чистый С и соответствующий стиль кода.
Во всех примерах намеренно не прописан using namespace std, чтобы было явно видно, какая функция из С, а какая из С++.

#### 2.5. А теперь пробуем собрать все вместе.

Теперь, когда вы умеете связывать процессы вместе, попробуйте собрать что-нибудь на этой механике. 
Это полностью настоящая параллельность - вы могли уже заметить, что разные процессы нагружают разные ядра процессоров.
Сделайте хотя бы одну из этих задач.

Если сложно и с ходу не получается, переходите к пункту 3. 
Та механика, на самом деле, попроще, но попробуйте вначале воспользоваться этой.

0. Сортировка большого массива. (Должно же стать быстрее, правда?..)
1. Обработка картинки. (Лучше всего попиксельный формат как в примере 07_ppm.cpp)
2. ...

В этом пункте вам надо не только проверить работоспособность написанного алгоритма, но и замерить время и построить график времени работы от количества процессов.
Чтобы проверить, насколько эффективно вы нагружаете ваш процессор, нужно посмотреть количество физических ядер.
Как и в лабе про make, вам нужна команда ```lscpu```.
Там нужно смотреть на эти строки:
```
Thread(s) per core:                 2
Core(s) per socket:                 6
Socket(s):                          1
```
Да, это те же самые треды.
Но то, что их по два на ядро (гипертрединг), не значит, что это ядро будет работать в два раза быстрее.
Там просто немного эффективнее делятся ресурсы.
Максимальное ускорение будет только от физических ядер - то есть количество сокетов, умноженное на количество ядер на сокет.
*Если у вас сложный ноутбуковый процессор с отдельным комплектом энергосберегающих ядер, картина становится сильно сложнее. Попробуйте разобраться, когда включаются какие, используя простые алгоритмы и графики их производительности.*

### 3. Потоки (threads).

Еще одна механика низкоуровневого распараллеливания, которая штатно приехала в С++ в 11 стандарте.
*До этого она была в boost, тоже удобно, но не настолько.*
На самом деле, чтобы занять несколько ядер, вам не обязательно создавать полноценные процессы с независимым адресным пространством. 
Можно создавать несколько тредов (threads, потоки) в рамках одного процесса. 
Каждый тред будет "висеть" на отдельном ядре процессора.

А вот с памятью есть нюансы. 
Если вы не помните, что такое сегменты памяти в рамках плоской модели памяти, лучше вспомните, там довольно коротко (https://youtu.be/TZ2ZGfWRsHQ?list=PLthfp5exSWEqMwhBP0K-djeFzp9wuKJ0_&t=2261).
Так вот, у тредов будет общий сегмент глобальных переменных, общий сегмент кода и общая куча. 
Но у каждого треда будет свой сегмент стека.

Вообще, механика тредов нужна для того, чтобы операционная система могла распределять вычислительные ресурсы. 
Поэтому все процессы, которые вы до сих пор запускали, на самом деле уже использовали треды - по одному на процесс.
Давайте теперь посмотрим простые примеры, как бы этих тредов сделать несколько.

Опять же, максимально ободранный минимальный пример лежит в ```08_threads.cpp```.
Собирать нужно с флагом ```-pthread```, иначе будут ошибки линковки.
Он показывает, как создать тред, а потом дождаться конца его выполнения в точке синхронизации.
Такие точки нужны, потому что только в них вы уверены, что тред отработал до конца, и с данными можно работать дальше.

Чтобы убедиться, что с кучей тоже все в порядке (она общая), посмотрите пример ```09_threads_heap.cpp```.
*Посмотрите - в смысле, как обычно, почитайте, скомпилируйте, запустите, поковыряйте, поэкспериментируйте.*

Придумайте способ, как проверить, один это процесс или все-таки несколько.
Дописывайте код, смотрите в диспетчер задач, анализируйте то, что видите.

А теперь попробуйте сделать то же самое, что в пункте 2.5, только с тредами.
Скорее всего, из-за общей памяти это будет гораздо проще.

### Выводы.

Как вы уже могли понять, это сильно разные механики распараллеливания с точки зрения кода и удобства работы.
Если нужна большая степень независимости и мало передачи данных, лучше процессы.
Если нужно много данных перекидывать туда-сюда, лучше треды.
При выборе инструмента, как и всегда, ориентируйтесь на то, чего вы хотите добиться в итоге.

В том случае, если вам нужно распараллелить вашу программу не в рамках одной машины с одним многоядерным процессором, а на большом кластере из нескольких машин (сотен и даже тысяч процессоров), вам понадобится библиотека MPI.
Она похожа на работу с процессами, только сложнее, со своими сложностями и нюансами.
Поэтому в рамках этого курса мы даже не пытаемся её погрызть, но если вы освоились с тем, как синхронизировать процессы и выбивать из них приличную производительность, то и на отдельных курсах про MPI, которые у вас будут, вам будет гораздо понятнее, что происходит.

А треды вам пригодятся гораздо раньше.
Это простая и неплохо работающая параллельность, которую вы можете прикрутить даже к небольшим расчетным проектам.
А ещё, например, сейчас часто раскидывают на отдельные треды отрисовку и обсчет игровых механик. 
Поэтому постарайтесь освоить оба инструмента.
Пригодятся.

## Что сдаем

На половину плюса - одна задача из 2.5, выполненная на тредах. 
Не забудьте графики.

На полный плюс - то же самое, только на процессах.
И тут тоже графики.
